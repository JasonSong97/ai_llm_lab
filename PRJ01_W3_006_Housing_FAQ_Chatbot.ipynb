{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  주택청약 FAQ 시스템 챗봇 구현 - 문서 전처리 + RAG + Gradio ChatInterface\n",
    "\n",
    "### 학습 목표\n",
    "\n",
    "1. 텍스트 문서를 로드하고 구조화된 Q&A 쌍으로 파싱\n",
    "2. LLM을 활용한 키워드 추출 및 요약 생성\n",
    "3. Chroma 벡터 데이터베이스에 문서 임베딩 저장\n",
    "4. MMR 검색 및 메타데이터 필터링 구현\n",
    "5. RAG 체인 구성 및 문서 관련성 평가\n",
    "6. Gradio를 사용한 대화형 챗봇 인터페이스 구현\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 준비\n",
    "\n",
    "**1. 환경 변수 설정**\n",
    "\n",
    "`.env` 파일에 다음 내용을 추가하세요:\n",
    "```\n",
    "OPENAI_API_KEY=your-api-key-here\n",
    "```\n",
    "\n",
    "**2. 필수 패키지 설치**\n",
    "```bash\n",
    "pip install langchain-openai langchain-community langchain-core\n",
    "pip install langchain-chroma chromadb\n",
    "pip install python-dotenv gradio\n",
    "```\n",
    "\n",
    "**3. 데이터 파일**\n",
    "- `data/housing_faq.txt` 파일 필요 (국토교통부 주택청약 FAQ 50개 Q&A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) LLM 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',      # 사용할 모델\n",
    "    temperature=0.1,            # 낮은 값: 일관된 답변 (0.0~2.0)\n",
    "    top_p=0.9,                  # 토큰 샘플링 확률 임계값 (0.0~1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **문서 전처리 파이프라인**\n",
    "\n",
    "* 문서 전처리의 첫 단계는 데이터 정제로, 원본 문서에서 불필요한 요소(HTML 태그, 특수문자, 중복 내용 등)를 제거하고 텍스트를 표준화하는 과정입니다. 이는 검색 품질과 직결되는 중요한 단계입니다.\n",
    "\n",
    "* 문서 청킹(Chunking)은 긴 문서를 의미 있는 작은 단위로 분할하는 과정으로, 문장 단위나 단락 단위로 나누되 문맥의 연속성을 유지하는 것이 핵심입니다. 이는 검색 정확도와 답변 생성의 품질에 직접적인 영향을 미칩니다.\n",
    "\n",
    "* 임베딩(Embedding) 생성은 텍스트를 고차원의 벡터로 변환하는 과정으로, 문서의 의미적 특성을 수치화하여 효율적인 검색을 가능하게 합니다. 이때 사용되는 임베딩 모델의 선택이 검색 성능을 좌우하는 중요한 요소가 됩니다.\n",
    "\n",
    "* 마지막으로 벡터 데이터베이스 색인화 단계에서는 생성된 임베딩을 효율적으로 저장하고 검색할 수 있는 구조로 변환합니다. 이는 대규모 문서 집합에서도 빠른 검색을 가능하게 하는 핵심 요소입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 문서 로드\n",
    "\n",
    "- 국토교통부 주택청약 FAQ에서 일부 내용(청약자격, 청약통장)을 발췌하여 재가공\n",
    "- Q1 ~ Q50까지 모두 50개의 문답이 포함된 텍스트 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로 설정\n",
    "faq_text_file = \"data/housing_faq.txt\"\n",
    "\n",
    "# 파일 읽기 - 파이썬 내장 함수 사용\n",
    "with open(faq_text_file, 'r') as f:\n",
    "    faq_text = f.read()\n",
    "\n",
    "# 파일 내용 확인\n",
    "print(faq_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] TextLoader를 사용하여, 텍스트 문서를 로드합니다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# TODO: TextLoader 클래스를 사용하여 FAQ 텍스트 파일을 로드\n",
    "loader = None\n",
    "docs = None\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 확인\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 메타데이터 확인\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 문서 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 각 질문과 답변을 쌍으로 추출하여 정리 (정규표현식 활용)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_qa_pairs(text):\n",
    "    qa_pairs = []\n",
    "    \n",
    "    # 텍스트를 라인별로 분리하고 각 라인의 앞뒤 공백 제거\n",
    "    lines = [line.strip() for line in text.split('\\n')]\n",
    "    current_question = None\n",
    "    current_answer = []\n",
    "    current_number = None\n",
    "    in_answer = False\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if not line:  # 빈 라인 처리\n",
    "            if in_answer and current_answer and i + 1 < len(lines) and lines[i + 1].startswith('Q'):\n",
    "                # 다음 질문이 시작되기 전 빈 줄이면 현재 QA 쌍 저장\n",
    "                qa_pairs.append({\n",
    "                    'number': current_number,\n",
    "                    'question': current_question,\n",
    "                    'answer': ' '.join(current_answer).strip()\n",
    "                })\n",
    "                in_answer = False\n",
    "                current_answer = []\n",
    "            continue\n",
    "            \n",
    "        # 새로운 질문 확인 (Q 다음에 숫자가 오는 패턴)\n",
    "        q_match = re.match(r'Q(\\d+)\\s+(.*)', line)\n",
    "        if q_match:\n",
    "            # 이전 QA 쌍이 있으면 저장\n",
    "            if current_question is not None and current_answer:\n",
    "                qa_pairs.append({\n",
    "                    'number': current_number,\n",
    "                    'question': current_question,\n",
    "                    'answer': ' '.join(current_answer).strip()\n",
    "                })\n",
    "            \n",
    "            # 새로운 질문 시작\n",
    "            current_number = int(q_match.group(1))\n",
    "            current_question = q_match.group(2).strip().rstrip('?') + '?'  # 질문 마크 정규화\n",
    "            current_answer = []\n",
    "            in_answer = False\n",
    "            \n",
    "        # 답변 시작 확인\n",
    "        elif line.startswith('A ') or (current_question and not current_answer and line):\n",
    "            in_answer = True\n",
    "            current_answer.append(line.lstrip('A '))\n",
    "            \n",
    "        # 기존 답변에 내용 추가\n",
    "        elif current_question is not None and (in_answer or not line.startswith('Q')):\n",
    "            if in_answer or (current_answer and not line.startswith('Q')):\n",
    "                current_answer.append(line)\n",
    "    \n",
    "    # 마지막 QA 쌍 처리\n",
    "    if current_question is not None and current_answer:\n",
    "        qa_pairs.append({\n",
    "            'number': current_number,\n",
    "            'question': current_question,\n",
    "            'answer': ' '.join(current_answer).strip()\n",
    "        })\n",
    "    \n",
    "    # 번호 순서대로 정렬\n",
    "    qa_pairs.sort(key=lambda x: x['number'])\n",
    "    \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA 쌍 추출\n",
    "qa_pairs = extract_qa_pairs(docs[0].page_content) \n",
    "\n",
    "print(f\"추출된 QA 쌍 개수: {len(qa_pairs)}\")\n",
    "print(f\"추출된 첫번째 QA: \\n{qa_pairs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) LLM으로 추가 정보를 추출`\n",
    "- 텍스트에서 키워드와 핵심 개념을 추출하는 체인\n",
    "- 메타데이터 or 본문(page_content)에 추가하여 검색에 활용    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# 출력 형식 정의\n",
    "class KeywordOutput(BaseModel):\n",
    "    keyword: str = Field(description=\"텍스트에서 추출한 가장 중요한 키워드(법률용어, 주제 등))\")\n",
    "    summary: str = Field(description=\"텍스트의 간단한 요약\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"당신은 텍스트 분석 전문가입니다. \n",
    "주어진 텍스트에서 중요한 키워드를 추출하고, 텍스트의 간단한 요약을 작성하는 것이 당신의 역할입니다.\n",
    "\n",
    "## 추출 지침:\n",
    "- 텍스트의 맥락을 고려하여 핵심 용어나 전문 용어를 추출합니다\n",
    "- 주요 아이디어나 원리, 개념을 포함합니다\n",
    "- 가장 중요한 키워드를 1개 추출합니다\n",
    "- 요약은 1문장으로 간결하게 작성합니다\n",
    "\n",
    "## 출력 형식:\n",
    "- keyword: 가장 중요한 키워드 \n",
    "- summary: 텍스트의 간단한 요약\"\"\"),\n",
    "    \n",
    "    (\"user\", \"다음 텍스트를 분석해주세요:\\n\\n{input_text}\")\n",
    "])\n",
    "\n",
    "# LCEL 체인 구성\n",
    "llm_with_structure = llm.with_structured_output(KeywordOutput) \n",
    "keyword_extractor = prompt | llm_with_structure\n",
    "\n",
    "# 텍스트 추출 테스트     \n",
    "result = keyword_extractor.invoke(qa_pairs[0]['question']+qa_pairs[0]['answer'])\n",
    "print(\"키워드:\", result.keyword)\n",
    "print(\"요약:\", result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) QA 쌍을 문자열 포맷팅하고 문서 객체로 변환`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def format_qa_pairs(qa_pairs):\n",
    "    \"\"\"\n",
    "    추출된 QA 쌍을 포맷팅하여 문서 객체로 변환\n",
    "    \"\"\"\n",
    "    processed_docs = []\n",
    "    for pair in qa_pairs:\n",
    "\n",
    "        # QA 쌍을 포맷팅\n",
    "        formatted_output = (\n",
    "            f\"[{pair['number']}]\\n\"\n",
    "            f\"질문: {pair['question']}\\n\"\n",
    "            f\"답변: {pair['answer']}\\n\"\n",
    "        )\n",
    "\n",
    "        # 키워드와 요약 추출\n",
    "        result = keyword_extractor.invoke(pair['question']+\"\\n\\n\"+pair['answer'])\n",
    "\n",
    "        # 문서 객체 생성\n",
    "        doc = Document(\n",
    "            page_content=formatted_output,\n",
    "            metadata={\n",
    "                'question_id': int(pair['number']),\n",
    "                'question': pair['question'],\n",
    "                'answer': pair['answer'],\n",
    "                'keyword': result.keyword,\n",
    "                'summary': result.summary\n",
    "            }\n",
    "        )\n",
    "        processed_docs.append(doc)\n",
    "\n",
    "    return processed_docs\n",
    "\n",
    "\n",
    "# QA 쌍 포맷팅\n",
    "formatted_docs = format_qa_pairs(qa_pairs)\n",
    "print(f\"포맷팅된 문서 개수: {len(formatted_docs)}\")\n",
    "\n",
    "# 문서 확인\n",
    "print(formatted_docs[0].page_content)\n",
    "print(\"-\" * 200)\n",
    "# 문서 메타데이터 확인\n",
    "pprint(formatted_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 저장\n",
    "output_file = \"data/housing_faq_formatted.json\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8-sig') as f:\n",
    "    json.dump([doc.model_dump() for doc in formatted_docs], f, indent=2, ensure_ascii=False)  # 한글이 유니코드로 변환되지 않도록 설정\n",
    "print(f\"포맷팅된 문서를 {output_file}에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] 문서 객체를 포맷팅하여 구성합니다.***\n",
    "\n",
    "- 요약문을 시맨틱 검색에 활용합니다. 다음 구조로 문서 객체를 생성합니다. \n",
    "    - page_content: 요약\n",
    "    - metadata: 기타 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def format_qa_pairs_with_summary(qa_pairs):\n",
    "    \"\"\"\n",
    "    추출된 QA 쌍을 포맷팅하여 문서 객체로 변환\n",
    "    \"\"\"\n",
    "    processed_docs = []\n",
    "    for pair in qa_pairs:\n",
    "\n",
    "        # 키워드와 요약 추출\n",
    "        result = None\n",
    "\n",
    "        # 문서 객체 생성\n",
    "        doc = None\n",
    "        \n",
    "        processed_docs.append(doc)\n",
    "\n",
    "    return processed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA 쌍 포맷팅\n",
    "summary_formatted_docs = format_qa_pairs_with_summary(qa_pairs) \n",
    "print(f\"포맷팅된 문서 개수: {len(summary_formatted_docs)}\")\n",
    "\n",
    "# 문서 확인\n",
    "print(summary_formatted_docs[0].page_content)\n",
    "print(\"-\" * 200)\n",
    "# 문서 메타데이터 확인\n",
    "pprint(summary_formatted_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 저장\n",
    "output_file = \"data/housing_faq_formatted_with_summary.json\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8-sig') as f:\n",
    "    json.dump([doc.model_dump() for doc in summary_formatted_docs], f, indent=2, ensure_ascii=False)  # 한글이 유니코드로 변환되지 않도록 설정\n",
    "print(f\"포맷팅된 문서를 {output_file}에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 로드\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "output_file = \"data/housing_faq_formatted.json\"\n",
    "\n",
    "with open(output_file, 'r', encoding='utf-8-sig') as f:\n",
    "    formatted_docs = [Document(**doc) for doc in json.load(f)]\n",
    "\n",
    "# 문서 확인\n",
    "print(formatted_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formatted_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 문서 벡터 저장\n",
    "vector_store = Chroma.from_documents(  \n",
    "    documents=formatted_docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"housing_faq_db\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] 요약 문서(summary_formatted_docs)를 벡터 스토어에 저장합니다.*** \n",
    "\n",
    "- OpenAI (text-embedding-3-small) 임베딩 모델 사용\n",
    "- Chroma DB 사용\n",
    "\n",
    "**힌트**:\n",
    "1. `Chroma.from_documents()` 메소드 사용\n",
    "2. `embedding` 파라미터에 OpenAIEmbeddings 인스턴스 전달\n",
    "3. `collection_name`과 `persist_directory` 지정\n",
    "4. `summary_formatted_docs` 변수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 로드\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "output_file = \"data/housing_faq_formatted_with_summary.json\"\n",
    "\n",
    "with open(output_file, 'r', encoding='utf-8-sig') as f:\n",
    "    summary_formatted_docs = [Document(**doc) for doc in json.load(f)]\n",
    "\n",
    "# 문서 확인\n",
    "print(summary_formatted_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 문서 벡터 저장\n",
    "vector_store_summary = None\n",
    "\n",
    "print(vector_store_summary._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 벡터 저장소 로드\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"housing_faq_db\",\n",
    "    persist_directory=\"./chroma_db\", \n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] 앞에서 저장한 요약문서 벡터 스토어를 로드합니다.*** \n",
    "\n",
    "- OpenAI (text-embedding-3-small) 임베딩 모델 사용\n",
    "- Chroma DB 사용\n",
    "\n",
    "**힌트**:\n",
    "1. `Chroma()` 생성자 사용 (from_documents가 아님)\n",
    "2. 저장 시 사용한 `collection_name`, `persist_directory` 동일하게 지정\n",
    "3. `embedding_function` 파라미터에 OpenAIEmbeddings 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요.\n",
    "\n",
    "\n",
    "# 벡터 저장소 로드\n",
    "vector_store_summary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 생성 - 유사도 기반 상위 3개 문서 검색\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "# 테스트 질문\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMR (Maximal Marginal Relevance)\n",
    "\n",
    "MMR은 검색 결과의 **관련성**과 **다양성**을 동시에 고려하는 알고리즘입니다.\n",
    "\n",
    "**주요 파라미터**:\n",
    "- `fetch_k`: 초기 검색 문서 수 (유사도 기준)\n",
    "- `k`: 최종 반환 문서 수\n",
    "- `lambda_mult`: 다양성 가중치\n",
    "  - `0.0`: 최대 다양성 (서로 다른 문서 우선)\n",
    "  - `1.0`: 최대 관련성 (유사도만 고려)\n",
    "  - `0.5`: 균형 (관련성과 다양성을 동등하게)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] MMR 검색기를 정의합니다.***  \n",
    "\n",
    "- 문서 벡터 스토어를 사용\n",
    "- 10개의 문서를 가져와서, 다양성 기반으로 3개를 선택 (다양성은 중간 수준 적용)\n",
    "\n",
    "**힌트**:\n",
    "1. `vector_store.as_retriever()` 메소드 사용\n",
    "2. `search_type=\"mmr\"` 파라미터 지정\n",
    "3. `search_kwargs`에 `fetch_k=10`, `k=3`, `lambda_mult=0.5` 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요.\n",
    "\n",
    "mmr_retriever = None\n",
    "\n",
    "# 테스트 질문\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = mmr_retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(result.metadata['question'])\n",
    "    print(result.metadata['answer'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[심화] 메타데이터 기반 필터링**\n",
    "\n",
    "- Chroma 문서: https://docs.trychroma.com/docs/querying-collections/metadata-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 필드 정확히 일치\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"keyword\": \"해당 주택건설지역\"}},\n",
    ")\n",
    "\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $eq 연산자 사용 - 정확히 일치\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"keyword\": {\"$eq\": \"해당 주택건설지역\"}}},\n",
    ")\n",
    "\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ne (Not Equal) 연산자 사용 - 정확히 일치하지 않는 문서 검색\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"keyword\": {\"$ne\": \"해당 주택건설지역\"}}},\n",
    ")\n",
    "\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $in 연산자로 여러 값 중 일치하는 문서 검색\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"keyword\": {\"$in\": [\"해당 주택건설지역\", \"청약예금\"]}}},\n",
    ")\n",
    "\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 범위 검색 ($gt, $gte, $lt, $lte) - question_id가 10 이상인 문서 검색\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"question_id\": {\"$gte\": 10}}},\n",
    ")\n",
    "\n",
    "query = \"무주택자 기준은 무엇인가요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $and로 여러 조건 조합 - keyword가 \"주택건설지역\"이고 question_id가 10 미만인 문서 검색\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"$and\": [\n",
    "        {\"keyword\": \"해당 주택건설지역\"}, \n",
    "        {\"question_id\": {\"$lt\": 10}}\n",
    "    ]}},\n",
    ")\n",
    "\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $or로 여러 조건 중 하나 일치하는 문서 검색 - keyword가 \"주택건설지역\"이거나 question_id가 10 이상인 문서 검색\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"$or\": [\n",
    "        {\"keyword\": \"해당 주택건설지역\"}, \n",
    "        {\"question_id\": {\"$gte\": 10}}\n",
    "    ]}},\n",
    ")\n",
    "\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규식 패턴 매칭 - page_content 본문에 \"주택건설지역\"이 포함된 문서 검색\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={'where_document': {'$contains': '해당 주택건설지역'}},\n",
    ")\n",
    "\n",
    "query = \"수원시의 '해당 주택건설지역'은 어디에 해당하나요?\"\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(result.metadata['keyword'])\n",
    "    print(result.metadata['question_id'])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] 메타데이터 필터링 조건을 적용하는 실습을 수행합니다..*** \n",
    "\n",
    "- 요약 문서 벡터 스토어 기반 MMR 검색기에 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메타데이터 필터 LLM 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Literal\n",
    "\n",
    "\n",
    "class MetadataFilter(BaseModel):\n",
    "    \"\"\"Chroma DB 메타데이터 필터 조건\"\"\"\n",
    "\n",
    "    # 키워드 필터\n",
    "    keyword: Optional[str] = Field(default=None, description=\"검색할 키워드\")\n",
    "    keyword_operator: Optional[Literal[\"$eq\", \"$ne\"]] = Field(\n",
    "        default=None, description=\"키워드 비교 연산자\"\n",
    "    )\n",
    "\n",
    "    # 질문 ID 범위 (하한)\n",
    "    question_id_min: Optional[int] = Field(default=None, description=\"질문 ID 최소값\")\n",
    "    question_id_min_operator: Optional[Literal[\"$gt\", \"$gte\"]] = Field(\n",
    "        default=None, description=\"최소값 연산자 ($gt: 초과, $gte: 이상)\"\n",
    "    )\n",
    "\n",
    "    # 질문 ID 범위 (상한)\n",
    "    question_id_max: Optional[int] = Field(default=None, description=\"질문 ID 최대값\")\n",
    "    question_id_max_operator: Optional[Literal[\"$lt\", \"$lte\"]] = Field(\n",
    "        default=None, description=\"최대값 연산자 ($lt: 미만, $lte: 이하)\"\n",
    "    )\n",
    "\n",
    "    # 논리 연산자\n",
    "    logical_operator: Optional[Literal[\"$and\", \"$or\"]] = Field(\n",
    "        default=\"$and\", description=\"복합 조건 결합 연산자\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 시스템 프롬프트\n",
    "METADATA_FILTER_SYSTEM_PROMPT = \"\"\"사용자 쿼리에서 Chroma DB 검색 필터 조건을 추출합니다.\n",
    "\n",
    "## 추출 규칙\n",
    "\n",
    "### 키워드 (keyword)\n",
    "- 특정 단어/주제 검색 시 해당 키워드 추출\n",
    "- keyword_operator: 일반적으로 \"$eq\" 사용\n",
    "\n",
    "### 질문 ID 범위\n",
    "- \"N번 이상\": question_id_min=N, question_id_min_operator=\"$gte\"\n",
    "- \"N번 초과\": question_id_min=N, question_id_min_operator=\"$gt\"\n",
    "- \"N번 이하\": question_id_max=N, question_id_max_operator=\"$lte\"\n",
    "- \"N번 미만\": question_id_max=N, question_id_max_operator=\"$lt\"\n",
    "- \"N~M번 사이\": 최소값과 최대값 모두 설정\n",
    "\n",
    "### 논리 연산자\n",
    "- 모든 조건 만족: \"$and\" (기본값)\n",
    "- 하나라도 만족: \"$or\"\n",
    "\n",
    "## 예시\n",
    "\n",
    "1. 키워드만: \"주택건설 관련 문서\"\n",
    "   → keyword=\"주택건설\", keyword_operator=\"$eq\"\n",
    "\n",
    "2. ID 범위: \"10번 이상 20번 이하\"\n",
    "   → question_id_min=10, question_id_min_operator=\"$gte\",\n",
    "     question_id_max=20, question_id_max_operator=\"$lte\"\n",
    "\n",
    "3. 복합 조건: \"청약통장 관련 40~50번 문서\"\n",
    "   → keyword=\"청약통장\", keyword_operator=\"$eq\",\n",
    "     question_id_min=40, question_id_min_operator=\"$gte\",\n",
    "     question_id_max=50, question_id_max_operator=\"$lte\",\n",
    "     logical_operator=\"$and\"\n",
    "\n",
    "해당 정보가 없으면 null 반환.\n",
    "\"\"\"\n",
    "\n",
    "# 메타데이터 추출 체인 구성\n",
    "metadata_extraction_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", METADATA_FILTER_SYSTEM_PROMPT),\n",
    "        (\"human\", \"{query}\")\n",
    "    ])\n",
    "    | llm.with_structured_output(MetadataFilter)\n",
    ")\n",
    "\n",
    "# 테스트: 필터 조건 추출\n",
    "query = \"'해당 주택건설지역' 관련 문서를 10번 이하인 문서중에서 검색해주세요\"\n",
    "filter_params = metadata_extraction_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"추출된 필터 파라미터:\")\n",
    "print(filter_params.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chroma_filter(filter_params: MetadataFilter) -> dict:\n",
    "    \"\"\"MetadataFilter를 Chroma DB 필터 딕셔너리로 변환\n",
    "    \n",
    "    Args:\n",
    "        filter_params: MetadataFilter 인스턴스\n",
    "        \n",
    "    Returns:\n",
    "        Chroma DB where 절에 사용할 필터 딕셔너리\n",
    "    \"\"\"\n",
    "    conditions = []\n",
    "\n",
    "    # 키워드 조건\n",
    "    if filter_params.keyword and filter_params.keyword_operator:\n",
    "        conditions.append({\n",
    "            \"keyword\": {filter_params.keyword_operator: filter_params.keyword}\n",
    "        })\n",
    "\n",
    "    # 질문 ID 최소값 조건\n",
    "    if filter_params.question_id_min is not None and filter_params.question_id_min_operator:\n",
    "        conditions.append({\n",
    "            \"question_id\": {filter_params.question_id_min_operator: filter_params.question_id_min}\n",
    "        })\n",
    "\n",
    "    # 질문 ID 최대값 조건\n",
    "    if filter_params.question_id_max is not None and filter_params.question_id_max_operator:\n",
    "        conditions.append({\n",
    "            \"question_id\": {filter_params.question_id_max_operator: filter_params.question_id_max}\n",
    "        })\n",
    "\n",
    "    # 조건 개수에 따른 필터 구성\n",
    "    if len(conditions) == 0:\n",
    "        return {}\n",
    "    elif len(conditions) == 1:\n",
    "        return conditions[0]\n",
    "    else:\n",
    "        logical_op = filter_params.logical_operator or \"$and\"\n",
    "        return {logical_op: conditions}\n",
    "\n",
    "\n",
    "# 테스트: 필터 딕셔너리 생성\n",
    "filter_dict = build_chroma_filter(filter_params)\n",
    "print(\"생성된 Chroma 필터:\")\n",
    "print(filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def metadata_filter_retriever(query: str):\n",
    "    \"\"\"메타데이터 필터를 추출하고 검색 수행\n",
    "    \n",
    "    Args:\n",
    "        query: 사용자 검색 쿼리\n",
    "        \n",
    "    Returns:\n",
    "        검색된 문서 리스트\n",
    "    \"\"\"\n",
    "    # 1. 필터 조건 추출\n",
    "    filter_params = metadata_extraction_chain.invoke({\"query\": query})\n",
    "\n",
    "    # 2. Chroma 필터로 변환\n",
    "    filter_dict = build_chroma_filter(filter_params)\n",
    "    print(f\"추출된 필터: {filter_dict}\")\n",
    "\n",
    "    # 3. 검색 실행\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_kwargs={\"filter\": filter_dict} if filter_dict else {}\n",
    "    )\n",
    "    return retriever.invoke(query)\n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "query = \"청약통장 관련 문서를 40번과 50번 사이의 문서 중에서 검색해주세요\"\n",
    "results = metadata_filter_retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n검색된 문서 수: {len(results)}\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n--- 문서 {i} ---\")\n",
    "    print(f\"내용: {result.page_content[:100]}...\")\n",
    "    print(f\"키워드: {result.metadata.get('keyword', 'N/A')}\")\n",
    "    print(f\"질문 ID: {result.metadata.get('question_id', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 쿼리 테스트\n",
    "test_queries = [\n",
    "    \"청약통장 관련 문서 찾아줘\",        # 키워드만\n",
    "    \"질문 ID 10번 이상인 문서\",         # ID 하한만\n",
    "    \"20번 이하 문서만 보여줘\",          # ID 상한만\n",
    "    \"10번에서 30번 사이 문서\",          # ID 범위\n",
    "    \"'해당 주택건설지역' 관련 10번 이하 문서\",  # 복합\n",
    "    \"청약통장 관련 40~50번 문서\",       # 복합 + 범위\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # 필터 추출 및 검색\n",
    "    filter_params = metadata_extraction_chain.invoke({\"query\": query})\n",
    "    filter_dict = build_chroma_filter(filter_params)\n",
    "    print(f\"필터: {filter_dict}\")\n",
    "    \n",
    "    # 검색 실행\n",
    "    results = metadata_filter_retriever.invoke(query)\n",
    "    print(f\"검색 결과: {len(results)}건\")\n",
    "    \n",
    "    if results:\n",
    "        print(f\"첫 번째 문서 - 키워드: {results[0].metadata.get('keyword')}, ID: {results[0].metadata.get('question_id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] 메타데이터 필터링 체인의 성능을 개선합니다.*** \n",
    "\n",
    "- (예시)\n",
    "    - 추가 예시 제공을 통해 필터링 적용 법위 확대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 참조 문서 없이 직접 답변을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Prompt\n",
    "template = '''Answer the question based only on the following context.\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question]\n",
    "{question}\n",
    "\n",
    "[Answer (in 한국어)]\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# 문서 포맷팅\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "# 검색기 생성 - 유사도 기반 상위 3개 문서 검색\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "\n",
    "# Chain 구성\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Chain 실행\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 참조 문서를 답변과 함께 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 문서와 포맷팅된 컨텍스트를 함께 반환하는 함수`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_context_and_docs(question: str) -> Dict:\n",
    "    \"\"\"문서와 포맷팅된 컨텍스트를 함께 반환\n",
    "    \n",
    "    Args:\n",
    "        question: 검색할 질문\n",
    "\n",
    "    Returns:\n",
    "        Dict: 문서와 포맷팅된 컨텍스트, 검색된 문서 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    # 검색 결과 가져오기\n",
    "    docs = retriever.invoke(question)\n",
    "    return {\n",
    "        \"question\": question,  # 질문\n",
    "        \"context\": format_docs(docs),   # 문서 포맷팅된 컨텍스트\n",
    "        \"source_documents\": docs   # 검색된 문서 리스트\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 컨텍스트와 질문을 입력으로 받아 답변을 생성하는 함수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def prompt_and_generate_answer(input_data: Dict) -> Dict:\n",
    "    \"\"\"컨텍스트와 질문을 입력으로 받아 답변을 생성\n",
    "\n",
    "    Args:\n",
    "        input_data (Dict): 컨텍스트와 질문이 포함된 딕셔너리\n",
    "\n",
    "    Returns:\n",
    "        Dict: 생성된 답변과 소스 문서 정보가 포함된 딕셔너리\n",
    "    \"\"\"\n",
    "\n",
    "    # LCEL 체인 구성 (StrOutputParser 사용)\n",
    "    answer_chain = prompt | llm | StrOutputParser()\n",
    "    answer = answer_chain.invoke({\n",
    "        \"question\":input_data[\"question\"],\n",
    "        \"context\":input_data[\"context\"]\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,  # 생성된 답변 (answer_chain 결과)\n",
    "        \"source_documents\": input_data[\"source_documents\"]  # 소스 문서 정보 (input_data에서 가져옴)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) RAG 체인 구성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "# Chain 구성\n",
    "rag_chain = (\n",
    "    RunnableLambda(get_context_and_docs) |  # 문서와 컨텍스트 가져오기 \n",
    "    {\n",
    "        'response': RunnableLambda(prompt_and_generate_answer), # 답변 생성\n",
    "        'question': itemgetter(\"question\"),  # 질문 그대로 전달\n",
    "        \"source_documents\": itemgetter(\"source_documents\")   # 소스 반환\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 실행\n",
    "query = \"수원시의 주택건설지역은 어디에 해당하나요?\"\n",
    "result = rag_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"답변:\", result[\"response\"][\"answer\"])\n",
    "print(\"\\n참조 문서:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "    print(f\"\\n문서 {i}:\")\n",
    "    print(f\"내용: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 검색 문서 관련성 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 검색 문서와 질문 간의 관련성을 평가`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 문서의 질문 관련성 평가\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"주어진 컨텍스트가 질문에 답변하는데 필요한 정보를 포함하고 있는지 논리적으로 평가하세요.\n",
    "단계적으로 진행하며, 평가결과에 대한 검증을 수행하세요.\n",
    "\n",
    "다음 기준 중 하나 이상을 충족할 경우 'Yes'로 답변하고, 모두 충족하지 못하면 'No'로 답변하세요:\n",
    "\n",
    "1. 컨텍스트가 질문에 답변하는데 필요한 정보를 직접적으로 포함하고 있는가?\n",
    "2. 컨텍스트의 정보로부터 답변에 필요한 내용을 논리적으로 추론할 수 있는가?\n",
    "3. 컨텍스트의 정보가 질문에 대한 답변을 제공할 수 있는가?\n",
    "\n",
    "'Yes' 또는 'No'로만 답변하세요.\"\"\"),\n",
    "    (\"human\", \"\"\"[컨텍스트]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{question}\"\"\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()    # gpt-4.1-mini 모델 사용\n",
    "\n",
    "for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "    print(f\"\\n문서 {i}:\")\n",
    "    print(f\"내용: {doc.page_content}\")\n",
    "    relevance = chain.invoke({\n",
    "        \"context\": doc.page_content,\n",
    "        \"question\": query\n",
    "    }).lower()\n",
    "\n",
    "    print(f\"평가 결과: {relevance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4.1 모델 사용\n",
    "\n",
    "llm_gpt4o = ChatOpenAI(\n",
    "    model='gpt-4.1',          # 사용할 모델\n",
    "    temperature=0.1,          # 낮은 값: 일관된 답변 (0.0~2.0)\n",
    "    top_p=0.9,                # 토큰 샘플링 확률 임계값 (0.0~1.0)\n",
    ")\n",
    "\n",
    "chain = prompt | llm_gpt4o | StrOutputParser()    # gpt-4.1 모델 사용\n",
    "\n",
    "for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "    print(f\"\\n문서 {i}:\")\n",
    "    print(f\"내용: {doc.page_content}\")\n",
    "    relevance = chain.invoke({\n",
    "        \"context\": doc.page_content,\n",
    "        \"question\": query\n",
    "    }).lower()\n",
    "\n",
    "    print(f\"평가 결과: {relevance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***[실습] 문서 관련성 평가 체인을 구조화 출력으로 구현합니다.*** \n",
    "\n",
    "- pydantic schema 사용\n",
    "- with_structured_output 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio 챗봇 인터페이스 (RAG 시스템 클래스 구현)\n",
    "\n",
    "다음 클래스는 RAG 시스템의 전체 파이프라인을 캡슐화합니다.\n",
    "\n",
    "**주요 메서드**:\n",
    "- `_format_docs()`: 검색된 문서를 컨텍스트 문자열로 변환\n",
    "- `_format_source_documents()`: 참조 문서를 사용자 친화적 형식으로 포맷\n",
    "- `_evaluate_relevance()`: 검색된 문서의 질문 관련성 평가\n",
    "- `_generate_answer()`: 컨텍스트 기반 답변 생성\n",
    "- `generate_answer()`: Gradio 인터페이스용 메인 함수\n",
    "\n",
    "**클래스 구조**:\n",
    "1. LLM 초기화 (답변 생성용, 관련성 평가용)\n",
    "2. 벡터 스토어 검색기 설정\n",
    "3. 프롬프트 템플릿 정의\n",
    "4. RAG 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Optional, Generator\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    context: str\n",
    "    source_documents: Optional[List]\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(\n",
    "            self, \n",
    "            llm: BaseChatModel, \n",
    "            eval_llm: BaseChatModel,\n",
    "            retriever: VectorStoreRetriever\n",
    "        ):\n",
    "        if not llm:\n",
    "            self.llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "        else:\n",
    "            self.llm = llm\n",
    "\n",
    "        if not eval_llm:\n",
    "            self.eval_llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "        else:\n",
    "            self.eval_llm = eval_llm\n",
    "\n",
    "        if not retriever:\n",
    "            raise ValueError(\"검색기(retriever)가 필요합니다.\")\n",
    "        else:\n",
    "            self.retriever = retriever\n",
    "        \n",
    "    def _format_docs(self, docs: List) -> str:\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    def _format_source_documents(self, docs: Optional[List]) -> str:\n",
    "        if not docs:\n",
    "            return \"\\n\\nℹ️ 관련 문서를 찾을 수 없습니다.\"\n",
    "        \n",
    "        formatted_docs = []\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            metadata = doc.metadata if hasattr(doc, 'metadata') else {}\n",
    "            source_info = []\n",
    "            \n",
    "            if 'question_id' in metadata:\n",
    "                source_info.append(f\"ID: {metadata['question_id']}\")\n",
    "            if 'keyword' in metadata:\n",
    "                source_info.append(f\"키워드: {metadata['keyword']}\")\n",
    "            if 'summary' in metadata:\n",
    "                source_info.append(f\"요약: {metadata['summary']}\")\n",
    "                \n",
    "            formatted_docs.append(\n",
    "                f\"📚 참조 문서 {i}\\n\"\n",
    "                f\"• {' | '.join(source_info) if source_info else '출처 정보 없음'}\\n\"\n",
    "                f\"• 내용: {doc.page_content}\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\\n\" + \"\\n\\n\".join(formatted_docs)\n",
    "    \n",
    "    def _check_relevance(self, docs: List, question: str) -> List:\n",
    "        \"\"\"문서의 관련성 확인\"\"\"\n",
    "\n",
    "        relevant_docs = []\n",
    "\n",
    "        if not docs:\n",
    "            return relevant_docs\n",
    "            \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"주어진 컨텍스트가 질문에 답변하는데 필요한 정보를 포함하고 있는지 평가하세요.\n",
    "\n",
    "        다음 기준 중 하나 이상을 충족할 경우 'Yes'로 답변하고, 모두 충족하지 못하면 'No'로 답변하세요:\n",
    "\n",
    "        1. 컨텍스트가 질문에 답변하는데 필요한 정보를 직접적으로 포함하고 있는가?\n",
    "        2. 컨텍스트의 정보로부터 답변에 필요한 내용을 논리적으로 추론할 수 있는가?\n",
    "\n",
    "        'Yes' 또는 'No'로만 답변하세요.\"\"\"),\n",
    "            (\"human\", \"\"\"[컨텍스트]\n",
    "        {context}\n",
    "\n",
    "        [질문]\n",
    "        {question}\"\"\")\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | self.eval_llm | StrOutputParser()\n",
    "\n",
    "        for doc in docs:\n",
    "            result = chain.invoke({\n",
    "                \"context\": doc.page_content,\n",
    "                \"question\": question\n",
    "            }).lower()\n",
    "\n",
    "            print(f\"문서 {doc.metadata['question_id']} 관련성 확인 결과: {result}\")\n",
    "            print(f\"문서 {doc.metadata['question_id']} 내용:\")\n",
    "            print(doc.page_content)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            if \"yes\" in result:\n",
    "                relevant_docs.append(doc)\n",
    "            \n",
    "        return relevant_docs\n",
    "    \n",
    "    def search_documents(self, question: str) -> SearchResult:\n",
    "        try:\n",
    "            docs = retriever.invoke(question)\n",
    "            print(f\"검색된 문서 개수: {len(docs)}\")\n",
    "            relevant_docs = self._check_relevance(docs, question) \n",
    "            print(f\"관련 문서 개수: {len(relevant_docs)}\")\n",
    "            \n",
    "            return SearchResult(\n",
    "                context=self._format_docs(relevant_docs) if relevant_docs else \"관련 문서를 찾을 수 없습니다.\",\n",
    "                source_documents=relevant_docs,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"문서 검색 중 오류 발생: {e}\")\n",
    "            return SearchResult(\n",
    "                context=\"문서 검색 중 오류가 발생했습니다.\",\n",
    "                source_documents=None,\n",
    "            )\n",
    "    \n",
    "    def generate_answer(self, message: str, history: List) -> Generator[str, None, None]:\n",
    "            \"\"\"Gradio 스트리밍 출력을 위한 제너레이터 함수\"\"\"\n",
    "            \n",
    "            # 1. 문서 검색 \n",
    "            search_result = self.search_documents(message)\n",
    "            \n",
    "            if not search_result.source_documents:\n",
    "                yield \"죄송합니다. 관련 문서를 찾을 수 없어 답변하기 어렵습니다. 다른 질문을 해주시겠습니까?\"\n",
    "                return\n",
    "                        \n",
    "            # 2. 프롬프트 템플릿 설정\n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"\"\"다음 지침을 따라 질문에 답변해주세요:\n",
    "                1. 주어진 문서의 내용만을 기반으로 답변하세요.\n",
    "                2. 문서에 명확한 근거가 없는 내용은 \"근거 없음\"이라고 답변하세요.\n",
    "                3. 답변하기 어려운 질문은 \"잘 모르겠습니다\"라고 답변하세요.\n",
    "                4. 추측이나 일반적인 지식을 사용하지 마세요.\"\"\"),\n",
    "                (\"human\", \"문서들:\\n{context}\\n\\n질문: {question}\")\n",
    "            ])\n",
    "            \n",
    "            # 3. RAG Chain 구성\n",
    "            chain = prompt | self.llm | StrOutputParser()\n",
    "            \n",
    "            full_answer = \"\"\n",
    "            try:\n",
    "                # 4. 스트리밍 실행 (chain.stream 사용)\n",
    "                for chunk in chain.stream({\n",
    "                    \"context\": search_result.context,\n",
    "                    \"question\": message\n",
    "                }):\n",
    "                    full_answer += chunk\n",
    "                    # 현재까지 생성된 텍스트를 Gradio UI에 즉시 반영\n",
    "                    yield full_answer\n",
    "                \n",
    "                # 5. 답변 생성이 완료된 후 참조 문서 추가\n",
    "                sources = self._format_source_documents(search_result.source_documents)\n",
    "                final_response = f\"{full_answer}\\n\\n---\\n{sources}\"\n",
    "                yield final_response\n",
    "                \n",
    "            except Exception as e:\n",
    "                yield f\"답변 생성 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "\n",
    "rag_system = RAGSystem(\n",
    "    llm=ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0),   \n",
    "    eval_llm=ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0),\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    ")\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=rag_system.generate_answer,\n",
    "    title=\"RAG QA 시스템\",\n",
    "    description=\"\"\"\n",
    "    질문을 입력하면 관련 문서를 검색하여 답변을 생성합니다.\n",
    "    모든 답변에는 참조한 문서의 출처가 표시됩니다.\n",
    "    \"\"\",\n",
    "    examples=[\n",
    "        [\"수원시의 주택건설지역은 어디에 해당하나요?\"],\n",
    "        [\"무주택 세대에 대해서 설명해주세요.\"],\n",
    "        [\"2순위로 당첨된 사람이 청약통장을 다시 사용할 수 있나요?\"],\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 데모 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **[실습] 주택청약 FAQ 시스템 구현**\n",
    "\n",
    "### **문제 설명**\n",
    "이전 코드를 기반으로 주택청약 FAQ 시스템을 다음 요구사항에 맞춰 개선합니다. \n",
    "\n",
    "1. 응답 품질 향상 (1개 이상)\n",
    "   - 생성된 답변의 품질을 평가 (답변이 불충분한 경우 예외 처리)\n",
    "   - 관련성 높은 FAQ 문서 검색 (임베딩 모델, 청크 크기, 벡터 검색 방법 등)\n",
    "\n",
    "2. 사용자 경험 개선 (1개 이상)\n",
    "   - 대화 이력 관리 기능 추가 (요약, 트리밍 기능 등 고려)\n",
    "   - 최근 대화 기반 컨텍스트 구성 \n",
    "   - 사용자 프로필 기반 맞춤 응답\n",
    "\n",
    "### **제약 조건**\n",
    "- Gradio ChatInterface 사용\n",
    "- RAG 구조 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
